<!DOCTYPE html>
<html lang="en">

<head>
    <title>Article 1</title>
    <meta charset="UTF-8">
    <meta content="width=device-width, initial-scale=1.0" name="viewport">
</head>

<body>
    <div class="ArticleHead">
        <h1 class="title"><b>Can privacy coexist with technology that reads and changes brain activity?</b></h1>
        <h2 class="subtitle">Ethicists, scientists and our readers consider the ethics of brain technology</h2>
        <br>
        <p class="par" id="0"> <span class="pers"> Laura Sanders </span></p>
        <br>
    </div>
    <div class="ArticleBody">
        <p class="par" id="1">Gertrude the pig rooted around a straw-filled pen, oblivious to the cameras and onlookers
            —
            and the 1,024
            electrodes eavesdropping on her brain signals. Each time the pig’s snout found a treat in a researcher’s
            hand, a
            musical jingle sounded, indicating activity in her snout-controlling nerve cells.</p>
        <p class="par" id="2">Those beeps were part of the big reveal on August 28 by <span class="pers"> Musk’s
            </span>company <span class="company">Neuralink</span>
            <q>In a lot of ways, it’s
                kind of like a Fitbit in your skull with tiny wires,</q> said <span class="pers">Musk,</span> founder
            of
            <span class="company">Tesla</span> and <span class="company">SpaceX</span> , of the new
            technology.
        </p>
        <p class="par" id="3">Neuroscientists have been recording nerve cell activity from animals for decades. But the
            ambitions of Musk and
            others to <span class="key">link humans with computers</span> are shocking in their reach. Future-minded
            entrepreneurs and researchers
            aim to listen in on our brains and perhaps even reshape thinking. Imagine being able to beckon our Teslas
            with
            our minds, Jedi-style.</p>
        <p class="par" id="4">Some scientists called Gertrude’s introduction a slick publicity stunt, full of
            unachievable
            promises. But Musk has surprised people before. <q>You can’t argue with a guy who built his own electric
                car
                and sent it to orbit
                around Mars,</q> says <span class="pers">Christof Koch</span>, a neuroscientist at the <span
                class="inst">Allen
                Institute for Brain Science</span> in <span class="pl">Seattle</span> .
        </p>
        <figure>
            <img src="imgs/Img1.1.jpg" class="img-fluid" alt="image1">
            <figcaption>
                <p>Whenever Gertrude’s snout touched something, nerve cells in her brain fired electrical signals
                    detected
                    by an implanted device (signals shown as wavy lines on black). Similar technology may one day help
                    people with paralysis or brain disorders.
                    NEURALINK</p>
            </figcaption>
        </figure>
        <p class="par" id="5">Whether <span class="company">Neuralink</span> will eventually merge brains and Teslas is
            beside the point. Musk isn’t the
            only dreamer
            chasing neurotechnology. Advances are coming quickly and span a variety of approaches, including external
            headsets that may be able to distinguish between hunger and boredom; implanted electrodes that translate
            intentions to speak into real words; and bracelets that use nerve impulses for typing without a keyboard.
        </p>

        <p class="par" id="6">Today, <a href="https://www.sciencenews.org/article/mind-motion">paralyzed people are already testing brain-computer interfaces</a> , a technology that
            connects brains to the
            digital world (SN: 11/16/13, p. 22). With brain signals alone, users have been able to shop online,
            communicate
            and <a href="https://www.sciencenews.org/article/paralyzed-woman-grips-sips-coffee-robot-arm">even use a prosthetic arm to sip from a cup </a> (SN: 6/16/12, p. 5). The ability to hear neural chatter,
            understand it and perhaps even modify it could change and improve people’s lives in ways that go well beyond
            medical treatments. But these abilities also raise questions about who gets access to our brains and for
            what
            purposes.</p>
        <div class="Op-box">
            <p>Readers' thoughts</p>
            <p>We asked members of the public for their take on the ethics of new brain technology. A sampling of their quotes are on the following pages.</p>
            <p><q>The thoughts of someone accessing a person’s brain is absolutely terrifying.</q>
            <br>
            <q>I have no wish/desire to be a zombie or a clone.</q></p>
        </div>
        <p class="par" id="7">Because of neurotechnology’s potential for both good and bad, we all have a stake in
            shaping
            how it’s created
            and, ultimately, how it is used. But most people don’t have the chance to weigh in, and only find out about
            these advances after they’re a fait accompli. So we asked <span class="inst">Science News</span> readers
            their
            views about recent
            neurotechnology advances. We described three main ethical issues — fairness, autonomy and privacy. Far and
            away,
            readers were most concerned about privacy.</p>

        <p class="par" id="8">The idea of allowing companies, or governments, or even health care workers access to the
            brain’s inner workings
            spooked many respondents. Such an intrusion would be the most important breach in a world where privacy is
            already rare. <q>My brain is the only place I know is truly my own</q>, one reader wrote.</p>

        <p class="par" id="8">Technology that can change your brain — nudge it to think or behave in certain ways — is
            especially worrisome to
            many of our readers. A nightmare scenario raised by several respondents: We turn into zombies controlled by
            others.</p>

        <p class="par" id="9">When these types of brain manipulations get discussed, several sci-fi scenarios come to
            mind,
            such as memories
            being wiped clean in the poignant 2004 film <span class="co">Eternal Sunshine of the Spotless Mind</span> ;
            ideas implanted into a
            person’s mind, as in the 2010 movie <span class="co">Inception</span> ; or people being tricked into
            thinking a
            virtual world is the real
            thing, as in the mind-bending 1999 thriller <span class="co">The Matrix</span>.</p>

        <p class="par" id="10">Today’s tech capabilities are nowhere near any of those fantasies. Still, <q>the here
                and
                now
                is just as
                interesting … and just as morally problematic</q>, says neuroethicist <span class="pers">Timothy
                Brown</span> of the <span class="inst">University of Washington</span>
            in <span class="pl"></span> Seattle. <q>We don’t need The Matrix to get our dystopia.</q> </p>

        <figure>
            <img src="imgs/img1.2.jpg" class="img-fluid" alt="image2">
            <figcaption>
                <p>The ability to nudge brain activity in certain directions raises ethical questions.
                    JULIA YELLOW</p>
            </figcaption>
        </figure>
        <p class="par" id="11">Today, codes of ethics and laws govern research, medical treatments and certain aspects
            of
            our privacy. But we
            have no comprehensive way to handle the privacy violations that might arise with future advances in brain
            science. <q>We are all flying by the seat of our pants here,</q> says <span class="pers">Rafael
                Yuste</span> ,
            a neurobiologist at <span class="inst">Columbia University</span>.
        </p>

        <p class="par" id="12">For now, ethics questions are being taken up in a piecemeal way. Academic researchers,
            bioethicists and
            scientists at private companies, such as <span class="company">IBM</span> and <span
                class="company">Facebook</span>, are discussing these questions among themselves.
            Large brain-research consortiums, <a href="https://www.sciencenews.org/article/brain-shot">such as the <span class="inst">U.S. BRAIN Initiative</span></a> (SN: 2/22/14,
            p.
            16), include funding for
            projects that address privacy concerns. Some governments, including <span class="inst">Chile’s national
                legislature</span>, are starting
            to address concerns raised by neurotechnology.</p>

        <p class="par" id="13">With such disjointed efforts, it’s no surprise that no consensus has surfaced. The few
            answers that exist are as
            varied as the people doing the asking.</p>
        <figure>
            <img src="imgs/img1.3.jpg" class="img-fluid" alt="image3">
            <figcaption>
                <p>Electrode bracelet. <br> A bracelet studded with electrodes can detect tiny nerve impulses on the
                    wrist.
                    The bracelet (shown) uses electromyography, which picks up the behavior of nerve cells that control
                    muscles, to eavesdrop on signals that move from the brain to hand muscles. Developed by New York
                    City–based CTRL-Labs, a neural interface company acquired by Facebook Reality Labs in 2019, the
                    bracelet
                    allows users to play chess in a virtual room, control a hand avatar and type with tiny movements
                    from
                    inside a pocket, for instance, without a keyboard, mouse or touch screen. The technology is still in
                    development.</p>
            </figcaption>
        </figure>
        <h3>Reading Thoughts</h3>
        <br>
        <p class="par" id="14">The ability to pull information directly from the brain — without relying on speaking,
            writing or typing — has
            long been a goal for researchers and doctors intent on helping people whose bodies can no longer move or
            speak.
            Already, implanted electrodes can record signals from the movement areas of the brain, allowing people to
            control robotic prostheses.</p>

        <p class="par" id="15">In <span class="date">January 2019</span> , researchers at <span class="inst">Johns
                Hopkins
                University</span> implanted electrodes in the brain of
            <span class="pers">Robert “Buz”
                Chmielewski</span>, who was left quadriplegic after a surfing accident. With signals from both sides of
            his
            brain,
            Chmielewski controlled two prosthetic arms to use a fork and a knife simultaneously to feed himself,
            researchers
            announced in a press release on December 10.
        </p>

        <p class="par" id="16"> <span class="pers">Robert “Buz” Chmielewski</span>, who has had quadriplegia since his
            teens, uses brain signals to
            feed himself some cake.
            Via electrodes implanted in both sides of his brain, he controls two robotic arms: one manipulates the knife
            and
            the other holds the fork.</p>

        <p class="par" id="17">Other research has decoded speech from the brain signals of a paralyzed man who is unable
            to
            speak. When the man
            saw the question, <q>Would you like some water?</q> on a computer screen, he responded with the text
            message,
            <q>No, Iam not thirsty,</q> using only signals in his brain. This feat, described November 19 at a
            symposium
            hosted by
            <span class="inst">Columbia University</span>, is another example of the tremendous progress under way in
            linking brains to computers.
        </p>

        <p class="par" id="18"> <q>Never before have we been able to get that kind of information without interacting
                with
                the
                periphery of your
                body, that you had to voluntarily activate,</q> says <span class="pers">Karen Rommelfanger</span> , a
            neuroethicist at <span class="inst">Emory University</span> in
            <span class="pl">Atlanta</span>. Speaking, sign language and writing, for instance, <q>all require several
                steps of your decision making,</q>
            she says.
        </p>

        <p class="par" id="19">Today, efforts to extract information from the brain generally require bulky equipment,
            intense computing power
            and, most importantly, a willing participant, <span class="pers">Rommelfanger</span> says. For now, an
            attempt
            to break into your mind
            could easily be thwarted by closing your eyes, or wiggling fingers, or even getting drowsy.</p>

        <p class="par" id="20">What’s more, <span class="pers">Rommelfanger</span> says, <q>I don’t believe that any
                neuroscientist knows what a mind is
                or what a thought
                is,</q> she says. <q>I am not concerned about mind reading, from the existing terrain of
                technologies.</q> </p>

        <p class="par" id="21">But that terrain may change quickly. <q>We are getting very, very close</q> to having
            the
            ability
            to pull private
            information from people’s brains, <span class="pers">Yuste</span> says, pointing to studies that have
            decoded
            what a person is looking at
            and what words they hear. Scientists from <span class="company">Kernel</span>, a neurotech company near
            <span class="pl">Los Angeles</span>, have invented a helmet,
            just now hitting the market, that is essentially a portable brain scanner that can pick up activity in
            certain
            brain areas.</p>

        <p class="par" id="22">For now, companies have only our behavior — our likes, our clicks, our purchase histories
            —
            to build eerily
            accurate profiles of us and estimate what we’ll do next. And we let them. <span class="key">Predictive
                algorithms</span> make good
            guesses, but guesses all the same. <q>With this neural data gleaned from neurotechnology, it may not be a
                guess
                anymore,</q> <span class="pers">Yuste</span> says. Companies will have the real thing, straight from
            the
            source.</p>

        <p class="par" id="23">Even subconscious thoughts might be revealed with further technological improvements,
            <span class="pers">Yuste</span>
            says. <q>That is the
                ultimate privacy fear, because what else is left?</q></p>

        <figure>
            <img src="imgs/img1.4.jpg" class="img-fluid" alt="image4">
            <figcaption>
                <p>Laser helmets. <br> A helmet sends laser beams through the skull and into the brain. After bouncing
                    off
                    tissue and blood, the particles of light return to detectors that measure oxygen levels. Those
                    levels
                    indicate where in the brain nerve cells are active, thus giving clues about mental processes. This
                    technology, called functional near-infrared spectroscopy, is the same that allows pulse oximeters to
                    measure oxygen levels in the blood. In early <span class="date">2021</span>, the neurotechnology
                    company
                    <span class="company">Kernel</span>, based near <span class="pl">Los Angeles</span>, began selling
                    Kernel Flow helmets (shown) to researchers who are using the tools to study
                    concussions, language and even dreaming.
                </p>
            </figcaption>
        </figure>
        <h3>Rewrite, revise</h3>
        <br>
        <p class="par" id="24">Technology that can change the brain’s activity already exists today, as medical
            treatments.
            These tools can
            detect and stave off a seizure in a person with epilepsy, for instance, or stop a tremor before it takes
            hold.
        </p>

        <p class="par" id="25">Researchers are testing systems for obsessive-compulsive disorder, addiction <a href="https://www.sciencenews.org/article/brain-electric-implants-treat-depression-closer-reality">and
            depression</a> (SN: 2/16/19, p. 22).
            But the power to precisely change a functioning brain directly — and as a result, a person’s behavior —
            raises
            worrisome questions.</p>

        <p class="par" id="26">The desire to persuade, to change a person’s mind, is not new, says <span
                class="pers">Marcello Ienca</span>, a
            bioethicist at <span class="inst">ETH Zurich</span>.
            Winning hearts and minds is at the core of advertising and politics. Technology capable of changing your
            brain’s
            activity with just a subtle nudge, however, <q>brings current manipulation risks to the next level,</q>
            Ienca
            says.
        </p>
        <div class="Op-box">
            <p><q>Imagine walking into McDonald’s and suddenlyyou have an irresistible urge for a cheeseburger (or 10)</q></p>
        </div>
        <p class="par" id="27">What happens if such influence finds a place outside the medical arena? A doctor might
            use
            precise
            brain-modifying technology to ease anorexia’s grip on a young person, but the same might be used for
            money-making purposes: <q>Imagine walking into McDonald’s and suddenly you have an irresistible urge for a
                cheeseburger (or 10),</q> one of our readers wrote.</p>
        <p class="par" id="28">Is the craving caused by real hunger? Or is it the result of a tiny neural nudge just as
            you
            drove near the
            golden arches? That neural intrusion could spark uncertainty over where that urge came from, or perhaps even
            escape notice altogether. <q>This is super dangerous,</q> <span class="pers">Yuste</span> says. <q>The
                minute
                you start stimulating the brain,
                you are going to be changing people’s minds, and they will never know about it, because they will
                interpret
                it
                as ‘that’s me.’ </q></p>

        <p class="par" id="29">Precise brain control of people is not possible with existing technology. But in a hint
            of
            what may be possible,
            scientists have already <a href="https://www.sciencenews.org/article/manipulating-nerve-cells-makes-mice-see-something-not-there"> created visions inside mouse brains </a>(SN: 8/17/19, p. 10). Using a technique called
            optogenetics to stimulate small groups of nerve cells, researchers made mice “see” lines that weren’t there.
            Those mice behaved exactly as if their eyes had actually seen the lines, says <span
                class="pers">Yuste</span>,
            whose research group
            performed some of these experiments. <q>Puppets,</q> he calls them</p>
        <figure>
            <img src="imgs/img1.5.jpg" class="img-fluid" alt="image5">
            <figure>
                <figcaption>
                <p>Once researchers or companies can change our brain activity, will neural privacy require special
                    protections? <br> JULIA YELLOW</p></figcaption>
            </figure>
        </figure>
        <h3>What to do?</h3>
        <br>
        <p class="par" id="30">As neurotechnology marches ahead, scientists, ethicists, companies and governments are
            looking for answers on
            how, or even whether, to regulate brain technology. For now, those answers depend entirely on who is asked.
            And
            they come against a backdrop of increasingly invasive technology that we’ve become surprisingly comfortable
            with.</p>

        <p class="par" id="31">We allow our smartphones to monitor where we go, what time we fall asleep and even
            whether
            we’ve washed our hands
            for a full 20 seconds. Couple that with the digital breadcrumbs we actively share about the diets we try,
            the
            shows we binge and the tweets we love, and our lives are an open book.</p>

        <p class="par" id="32">Those details are more powerful than brain data, says <span class="pers">Anna
                Wexler</span>,
            an ethicist at the
            <span class="inst">University of Pennsylvania</span>.
            <q>My e-mail address, my notes app and my search engine history are more reflective of who I am as a person
                —my
                identity — than our neural data may ever be,
            </q> she says.
        </p>
        <div class="Op-box">
           <p><q>How would we know that what we thought or felt came from our own brains, or whether it was put there by someone else?</q></p> 
        </div>
        <p class="par" id="33">It’s too early to worry about privacy invasions from neurotechnology, <span
                class="pers">Wexler</span> argues, a
            position that makes her an
            outlier. <q>Most of my colleagues would tell me I’m crazy.</q></p>

        <p class="par" id="34">At the other end of the spectrum, some researchers, including <span
                class="pers">Yuste</span>, have proposed strict
            regulations around
            privacy that would treat a person’s neural data like their organs. Much like a liver can’t be taken out of a
            body without approval for medical purposes, neural data shouldn’t be removed either. That viewpoint has
            found
            purchase in Chile, which is now considering whether to classify neural data with new protections that would
            not
            allow companies to get at it.</p>

        <p class="par" id="35">Other experts fall somewhere in the middle. <span class="pers">Ienca</span>, for example,
            doesn’t want to see
            restrictions on personal
            freedom. People ought to have the choice to sell or give away their brain data for a product they like, or
            even
            for straight up cash. <q>The human brain is becoming a new asset,</q> <span class="pers">Ienca</span>
            says,
            something that can generate profit
            for companies eager to mine the data. He calls it <q>neurocapitalism.</q></p>

        <p class="par" id="36">And <span class="pers">Ienca</span> is fine with that. If a person is adequately informed
            —
            granted, a questionable if
            — then they are
            within their rights to sell their data, or exchange it for a service or product, he says. People ought to
            have
            the freedom to do what they like with their information.</p>

        <p class="par" id="37">General rules, checklists and regulations are not likely to be a good path forward,
            <span class="pers">Rommelfanger</span> says. <q>Right
                now, there are over 20 frameworks, guidelines, principles that have been developed since 2014 on how to
                handle
                neuroscience,</q> she says. Those often cover <span class="key">“mental privacy”</span> and <span
                class="key">“cognitive liberty,”</span> the freedom to control your
            own mental life.
        </p>

        <p class="par" id="38">Those guidelines are thoughtful, she says, but the technologies differ in what they’re
            capable of, and in their
            possible ethical repurcussions. One-size-fits-all solutions don’t exist, <span
                class="pers">Rommelfanger</span>
            says.</p>
        <figure>
            <img src="imgs/img1.6.jpg" class="img-fluid" alt="image6">
            <figcaption>
                <p>Under-skull implants. <br> Thin tendrils laced with hundreds or thousands of electrodes will spread
                    out
                    in the brain to listen in on — and perhaps even stimulate — nerve cells. So far, Elon Musk’s company
                    Neuralink, based in Fremont, Calif., has tried the method on rats and pigs in the lab. Other labs
                    are
                    testing implanted electrodes in people with paralysis. To make the surgery less risky and more
                    efficient, Neuralink is building a robot that can quickly sew the electrode threads (shown attached
                    to a
                    charging disk) into the brain, ultimately linking people with computers.</p>
            </figcaption>
        </figure>
        <p class="par" id="39">Instead, each company or research group may need to work through ethical issues
            throughout
            the development
            process. She and colleagues have recently <a href="https://www.cell.com/neuron/pdfExtended/S0896-6273(18)30823-7">proposed five questions</a> that researchers can ask themselves to
            begin
            thinking about these ethical issues, including privacy and autonomy. The questions ask people to consider
            how
            new technology might be used outside of a lab, for instance.</p>

        <p class="par" id="40">Moving forward on the technology to help people with mental illness and paralysis is an
            ethical imperative,
            <span class="pers">Rommelfanger</span> says.<q> More than my fear of a privacy violation, my fear is about
                diminished public trust that
                could undermine all of the good this technology could do.</q>
        </p>

        <p class="par" id="41">A lack of ethical clarity is unlikely to slow the pace of the coming neurotech rush. But
            thoughtful consideration
            of the ethics could help shape the trajectory of what’s to come, and help protect what makes us most human.
        </p>
        <div class="citations">
            <h2>
                CITATIONS
            </h2>
            <ol>
                <li>J. H. Marshel et al. Cortical layer-specific critical dynamics triggering perception. Science. Vol. 365, August 9, 2019. doi: 10.1126/science.aaw5202.</li>
                <li>L. Carillo-Reid et al. Controlling visually guided behavior by holographic recalling of cortical ensembles. Cell. Vol. 178, July 11, 2019. doi: 10.1016/j.cell.2019.05.045.</li>
                <li>R. Yuste et al. Four ethical priorities for neurotechonlogies and AI. Nature. November 8, 2017. doi: 10.1038/551159a.</li>
                <li>K. S. Rommelfanger et al. “Neuroethics questions to guide ethical research in the international brain initiatives.” Neuron. October 10, 2018. doi: 10.1016/j.neuron.2018.09.021.</li>
            </ol>
        </div>
    </div>
</body>

</html>